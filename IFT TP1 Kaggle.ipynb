{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Layer\n",
    "import keras.backend as K\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense, Input, Dense, concatenate\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.optimizers import Optimizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPTIMIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Optimizer\n",
    "\n",
    "class AdamIFT6135(Optimizer):\n",
    "    def __init__(self, lr=0.001, beta_1=0.9, beta_2=0.999,\n",
    "                 decay=0., use_momentum=True, use_rms=True, **kwargs):\n",
    "        \"\"\"\n",
    "            use_momentum = True ... SGD with momentum\n",
    "            use_rms = True ... RMSProp\n",
    "            both = True ... Adam\n",
    "        \"\"\"\n",
    "        #The parent class optimizer passes the following: self.updates, self.weights which\n",
    "        #are both lists. Also, you inherit 'clipnorm' and 'clipvalue' as allowed arguments\n",
    "        #The methods inherited are: get_updates which must be overriden and this is where the\n",
    "        #optimization logic must be implemented, get_gradients, set_weights and get_weights\n",
    "        super(AdamIFT6135, self).__init__(**kwargs)\n",
    "\n",
    "        #Equivalent to with tf.name_scope('block1'). I took it from the\n",
    "        #way that the in-package optimizers are developed, but I am not\n",
    "        #sure about the pros and cons of using the name_scope vs just ignoring it.\n",
    "        #But I assume it's a best practice.\n",
    "        #https://stackoverflow.com/questions/42708989/why-do-we-use-tf-name-scope\n",
    "        with K.name_scope(self.__class__.__name__):\n",
    "            # A counter for iterations, useful for moving averages\\momentum computation\n",
    "            self.iterations = K.variable(0, dtype='int64', name='iterations')\n",
    "            self.lr = K.variable(lr, name='lr')\n",
    "            self.beta_1 = K.variable(beta_1, name='beta_1')\n",
    "            self.beta_2 = K.variable(beta_2, name='beta_2')\n",
    "            self.decay = K.variable(decay, name='decay')\n",
    "            self.initial_decay = decay\n",
    "            self.epsilon = K.epsilon()\n",
    "\n",
    "            if not (use_momentum or use_rms):\n",
    "                print(\"You must choose at least momentum or rms\")\n",
    "                return None\n",
    "            self.use_momentum = use_momentum\n",
    "            self.use_rms = use_rms\n",
    "        \n",
    "    def get_updates(self, loss, params):\n",
    "        \"\"\"\n",
    "        This function is called once and only once. So whatever local variables are going\n",
    "        to live as long as the optimizer object is living\n",
    "        https://github.com/keras-team/keras/issues/4746\n",
    "        https://stackoverflow.com/questions/41787873/how-adagrad-wroks-in-keras-what-does-self-weights-mean-in-keras-optimizer\n",
    "        - Store your weights as GPU variables and update them with functions.\n",
    "        - for all optimizers in Keras get_updates() implements the tensor logic for one step of updates\n",
    "        \"\"\"\n",
    "        #Compute the gradients according to the loss and weights\n",
    "        grads = self.get_gradients(loss, params)\n",
    "        \n",
    "        #It is not clear the role of self.updates in Keras, but apparently they exist for writing\n",
    "        #even custom layers. I will just honor their way of doing things and will update the \n",
    "        #newly computed parameters in an append to this list.\n",
    "        #self.updates (list of update tuples (tensor, new_tensor)).\n",
    "        #Increment the self.iterations\n",
    "        self.updates = [K.update_add(self.iterations, 1)]\n",
    "        #t for the bias correction, I took this implementation from the library, casting to float\n",
    "        t = K.cast(self.iterations, K.floatx()) + 1\n",
    "        \n",
    "        #In the beginning we don't know the shape of the network, so the moving average\n",
    "        #accumulators cannot be initialized in the constructor. So we initialize them here.\n",
    "        #As explained, we create the accumulators initialized with zeros\n",
    "        #https://www.coursera.org/learn/deep-neural-network/lecture/w9VCZ/adam-optimization-algorithm\n",
    "        #So we create a list for each layer, each item is a zero matrix with the shape of the layer\n",
    "        if self.use_momentum and not self.use_rms:\n",
    "            v_dws = [K.zeros(K.int_shape(p)) for p in params]\n",
    "            self.weights = v_dws\n",
    "        elif self.use_rms and not self.use_momentum:\n",
    "            s_dws = [K.zeros(K.int_shape(p)) for p in params]\n",
    "            self.weights = s_dws\n",
    "        else:\n",
    "            v_dws = [K.zeros(K.int_shape(p)) for p in params]\n",
    "            s_dws = [K.zeros(K.int_shape(p)) for p in params]\n",
    "            self.weights = [self.iterations] + v_dws + s_dws\n",
    "        \n",
    "        #Update each layer\n",
    "        for param, grad, v_dw, s_dw in zip(params, grads, v_dws, s_dws):\n",
    "            if self.use_momentum:\n",
    "                v_dw_original = (self.beta_1 * v_dw) + ((1 - self.beta_1) * grad)\n",
    "                #bias correction\n",
    "                v_dw_corrected = v_dw_original / (1. - K.pow(self.beta_1, t))\n",
    "                \n",
    "            if self.use_rms:\n",
    "                s_dw_original = (self.beta_2 * s_dw) + ((1 - self.beta_2) * K.square(grad))\n",
    "                #bias correction\n",
    "                s_dw_corrected = s_dw_original / (1. - K.pow(self.beta_2, t))\n",
    "                \n",
    "            #Update\n",
    "            if self.use_momentum and not self.use_rms:\n",
    "                #SGD with momentum update\n",
    "                update = param - (self.lr * v_dw_corrected)\n",
    "                #We update the original ones, not the bias corrected values\n",
    "                self.updates.append(K.update(v_dw, v_dw_original))\n",
    "            elif self.use_rms and not self.use_momentum:\n",
    "                #RMSProp Update\n",
    "                update = param - (self.lr * grad) / (K.sqrt(s_dw_corrected) + self.epsilon)\n",
    "                self.updates.append(K.update(s_dw, s_dw_original))\n",
    "            else:\n",
    "                #Adam Update\n",
    "                #Also unclear from the documentation why not write directly to the variable\n",
    "                update = param - self.lr * v_dw_corrected / (K.sqrt(s_dw_corrected) + self.epsilon)\n",
    "                \n",
    "            \n",
    "            \n",
    "            self.updates.append(K.update(param, update))\n",
    "            \n",
    "        return self.updates\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {'lr': float(K.get_value(self.lr)),\n",
    "                  'beta_1': float(K.get_value(self.beta_1)),\n",
    "                  'beta_2': float(K.get_value(self.beta_2))}\n",
    "        base_config = super(AdamIFT6135, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_inception_layer(x, n_filters):\n",
    "    \"\"\"\n",
    "    Input is passed in parallel through the following:\n",
    "        1x1 conv\n",
    "        1x1 conv --> 3x3 conv\n",
    "        1x1 conv --> 5x5 conv\n",
    "        maxpool_3x3 --> 3x3 conv\n",
    "        \n",
    "    n_filters: all filters will have the same number of channels, for simplicity\n",
    "    \"\"\"\n",
    "    \n",
    "    conv_1x1 = Conv2D(n_filters, (1, 1), padding='same', activation='relu')(x)\n",
    "    \n",
    "    conv_1x1_3x3 = Conv2D(n_filters, (1, 1), padding='same', activation='relu')(x)\n",
    "    conv_1x1_3x3 = Conv2D(n_filters, (3, 3), padding='same', activation='relu')(conv_1x1_3x3)\n",
    "    \n",
    "    conv_1x1_5x5 = Conv2D(n_filters, (1, 1), padding='same', activation='relu')(x)\n",
    "    conv_1x1_5x5 = Conv2D(n_filters, (5, 5), padding='same', activation='relu')(conv_1x1_5x5)\n",
    "    \n",
    "    maxpl_3x3_conv_3x3 = MaxPooling2D(pool_size=(3, 3),strides=(1, 1), padding='same')(x)\n",
    "    maxpl_3x3_conv_3x3 = Conv2D(n_filters, (3, 3), padding='same', activation='relu')(maxpl_3x3_conv_3x3)\n",
    "    #print(conv_1x1, conv_1x1_3x3, conv_1x1_5x5, maxpl_3x3_conv_3x3)\n",
    "    inception = concatenate([conv_1x1, conv_1x1_3x3, conv_1x1_5x5, maxpl_3x3_conv_3x3], axis=3)\n",
    "    \n",
    "    return inception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The following layers were not used in the final model, but were only included for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDropout(Layer):\n",
    "    \"\"\"\n",
    "    This layer was not used, only included for reference\n",
    "    \"\"\"\n",
    "    def __init__(self, rate, **kwargs):\n",
    "        super(SimpleDropout, self).__init__(**kwargs)\n",
    "        self.rate = min(1., max(0., rate))\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        if 0. < self.rate < 1.:\n",
    "            def dropped_inputs():\n",
    "                mask = K.cast(K.random_uniform( K.shape(inputs) ) >= self.rate, 'float32')\n",
    "                return inputs * mask\n",
    "            \n",
    "            #in_train_phase returns the first argument in training, the second otherwise\n",
    "            return K.in_train_phase(dropped_inputs, \n",
    "                                    inputs,\n",
    "                                    training=training)\n",
    "        return inputs\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'rate': self.rate}\n",
    "        base_config = super(SimpleDropout, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/understanding-residual-networks-9add4b664b03\n",
    "def simple_res_double_ception(x, n_filters):\n",
    "    res = x\n",
    "    incept = simple_inception_layer(x, n_filters)\n",
    "    incept = simple_inception_layer(incept, n_filters)\n",
    "    return add([res,incept])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Add, Dense, Activation\n",
    "\n",
    "def res_block(x, n_filters):\n",
    "    identity_shortcut = Conv2D(n_filters, (1, 1), border_mode='same', activation=None)(x)\n",
    "    main_flow = Conv2D(n_filters, (3, 3), border_mode='same', activation='relu')(x)\n",
    "    main_flow = Conv2D(n_filters, (3, 3), border_mode='same', activation=None)(x)\n",
    "    addition = Add()([main_flow, identity_shortcut])\n",
    "    activated = Activation('relu')(addition)\n",
    "    #print(K.int_shape(activated))\n",
    "    return activated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA LOADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height, img_width, n_channels = (64, 64, 3)\n",
    "\n",
    "input_shape = (img_height, img_width, n_channels)\n",
    "\n",
    "train_data_dir = './trainset/'\n",
    "\n",
    "batch_size=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/42443936/keras-split-train-test-set-when-using-imagedatagenerator\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2) # set validation split\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    subset='training') # set as training data\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir, # same directory as training data\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    subset='validation') # set as validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8x%\n",
    "input_img = Input(shape=input_shape)\n",
    "\n",
    "initial_path = Conv2D(32, (3, 3), border_mode='same', activation='relu')(input_img)\n",
    "initial_path = Conv2D(32, (3, 3), border_mode='same', activation='relu')(initial_path)\n",
    "initial_path = MaxPooling2D(pool_size=(2, 2))(initial_path)\n",
    "\n",
    "initial_path = Conv2D(64, (3, 3), border_mode='same', activation='relu')(initial_path)\n",
    "initial_path = Conv2D(64, (3, 3), border_mode='same', activation='relu')(initial_path)\n",
    "initial_path = MaxPooling2D(pool_size=(2, 2))(initial_path) #16x16x64\n",
    "\n",
    "initial_path  = simple_inception_layer(initial_path, 64)\n",
    "\n",
    "initial_path = Conv2D(128, (3, 3), border_mode='same', activation='relu')(initial_path)\n",
    "initial_path = Conv2D(128, (3, 3), border_mode='same', activation='relu')(initial_path)\n",
    "initial_path = MaxPooling2D(pool_size=(2, 2))(initial_path)\n",
    "\n",
    "initial_path  = simple_inception_layer(initial_path, 64)\n",
    "\n",
    "initial_path = Conv2D(256, (3, 3), border_mode='same', activation='relu')(initial_path)\n",
    "initial_path = Conv2D(256, (3, 3), border_mode='same', activation='relu')(initial_path)\n",
    "initial_path = MaxPooling2D(pool_size=(2, 2))(initial_path)\n",
    "\n",
    "initial_path  = simple_inception_layer(initial_path, 64)\n",
    "#initial_path  = simple_inception_layer(initial_path, 16)\n",
    "\n",
    "x = Flatten()(initial_path)\n",
    "\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "out = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "inception_model = Model(input_img, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = AdamIFT6135( lr=0.00001, beta_1=0.9, beta_2=0.999, decay=0., use_momentum=False, use_rms=True)\n",
    "\n",
    "inception_model.compile(loss='binary_crossentropy',\n",
    "            optimizer=optim,\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "hist_inception=inception_model.fit_generator(train_generator,\n",
    "                           validation_data = validation_generator,\n",
    "                           steps_per_epoch = np.ceil(train_generator.samples / batch_size),#train_generator.samples, \n",
    "                            validation_steps = np.ceil(validation_generator.samples / batch_size),#validation_generator.samples ,\n",
    "                           epochs=80,\n",
    "                           verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change these for contiuing the training with different settings\n",
    "#optim = AdamIFT6135( lr=0.00001, beta_1=0.9, beta_2=0.9, decay=0., use_momentum=False, use_rms=True)\n",
    "#K.set_value(inception_model.optimizer.lr, 0.00001)\n",
    "#k.set_value(inception_model.optimizer.use_momentum, False)\n",
    "#k.set_value(inception_model.optimizer.beta_2, 0.9)\n",
    "\n",
    "hist_inception2=inception_model.fit_generator(train_generator,\n",
    "                           validation_data = validation_generator,\n",
    "                           steps_per_epoch = np.ceil(train_generator.samples / batch_size),#train_generator.samples, \n",
    "                            validation_steps = np.ceil(validation_generator.samples / batch_size),#validation_generator.samples ,\n",
    "                           epochs=8,\n",
    "                           verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate the history of different runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = [hist_inception.history, hist_inception2.history, hist_inception3.history]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_h = concat_histories(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(h):\n",
    "    items = list(h.keys())\n",
    "    x_range = range(1, len(h[items[0]])+1 )\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    ax = plt.subplot(111)\n",
    "\n",
    "    for i in items:\n",
    "        ax.plot(x_range, h[i], label=i)\n",
    "        \n",
    "    box = ax.get_position()\n",
    "    ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "\n",
    "    # Put a legend to the right of the current axis\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = './testset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1. / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory=test_path,\n",
    "    target_size=(64, 64),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=1,\n",
    "    class_mode=None,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = inception_model.predict_generator(test_generator, 4999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_file = [{\"id\":fname[5:-4], \"label\":\"Dog\" if pred >= 0.5 else \"Cat\", \"prob\":float(pred)} for fname, pred in zip(test_generator.filenames, preds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df = pd.DataFrame(preds_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df.id = preds_df.id.astype(int).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df.sort_values('id', inplace=True)\n",
    "preds_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df[['id','label']].to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used the code for visualizing the filters from https://fairyonice.github.io/Visualization%20of%20Filters%20with%20Keras.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting images with different confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_imgs(list_imgs, n_rows=2, n_cols=5):\n",
    "    \"\"\"\n",
    "    Note that the function is not checking for the indices, so make sure the \n",
    "    list of images path has the same number of n_rows x n_cols\n",
    "    \"\"\"\n",
    "    f, axs = plt.subplots(n_rows,n_cols)\n",
    "    img_counter = 0\n",
    "    for i in range(n_rows):\n",
    "        for j in range(n_cols):\n",
    "            image = mpimg.imread(list_imgs[img_counter])\n",
    "            axs[i,j].imshow(image)\n",
    "            img_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some predictions from the training set\n",
    "val_preds = model2.predict_generator(validation_generator, steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_file = [{\"id\":fname, \"actual\":fname[:3],\"prediction\":\"Dog\" if pred >= 0.5 else \"Cat\", \"prob\":float(pred)} for fname, pred in zip(validation_generator.filenames, val_preds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "preds_df = pd.DataFrame(preds_file)\n",
    "#preds_df.id = preds_df.id.astype(int).sort_values()\n",
    "preds_df.sort_values('id', inplace=True)\n",
    "preds_df.reset_index(inplace=True, drop=True)\n",
    "preds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of getting low confidence images\n",
    "x = [\"./trainset/\"+ img for img in list(preds_df[ (preds_df['prob'] > 0.45) & (preds_df['prob'] < 0.55) ].sample(frac=1)[10:20].id) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_imgs(x, n_rows=2, n_cols=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
